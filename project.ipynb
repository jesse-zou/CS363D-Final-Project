{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project\n",
    "Group Members: Jesse Zou, Andy Li, Yuhan Zheng, Zhiyao Bao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "What is the data science problem you are trying to solve?\n",
    "Why does the problem matter?\n",
    "What could the results of your predictive model be used for?\n",
    "Why would we want to be able to predict the thing youâ€™re trying to predict?\n",
    "Then describe the dataset that you will use to tackle this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data cleaning\n",
    "data exploration\n",
    "feature engineering\n",
    "describe and clarify each part of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>ExchangeRate</th>\n",
       "      <th>VIX</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12266.63965</td>\n",
       "      <td>12659.82031</td>\n",
       "      <td>12266.46973</td>\n",
       "      <td>12654.36035</td>\n",
       "      <td>295530000.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.5615</td>\n",
       "      <td>22.68</td>\n",
       "      <td>897.00</td>\n",
       "      <td>100.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12651.66992</td>\n",
       "      <td>12696.29004</td>\n",
       "      <td>12555.16992</td>\n",
       "      <td>12608.91992</td>\n",
       "      <td>232760000.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.5618</td>\n",
       "      <td>23.43</td>\n",
       "      <td>893.50</td>\n",
       "      <td>104.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12605.83008</td>\n",
       "      <td>12675.12012</td>\n",
       "      <td>12527.75000</td>\n",
       "      <td>12626.03027</td>\n",
       "      <td>183870000.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.5667</td>\n",
       "      <td>23.21</td>\n",
       "      <td>898.25</td>\n",
       "      <td>103.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12626.03027</td>\n",
       "      <td>12688.48047</td>\n",
       "      <td>12528.16016</td>\n",
       "      <td>12609.41992</td>\n",
       "      <td>181260000.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.5735</td>\n",
       "      <td>22.45</td>\n",
       "      <td>905.25</td>\n",
       "      <td>106.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12612.58984</td>\n",
       "      <td>12733.66016</td>\n",
       "      <td>12583.28027</td>\n",
       "      <td>12612.42969</td>\n",
       "      <td>198070000.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.5713</td>\n",
       "      <td>22.42</td>\n",
       "      <td>914.70</td>\n",
       "      <td>108.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL         Open         High          Low        Close       Volume  \\\n",
       "0      0  12266.63965  12659.82031  12266.46973  12654.36035  295530000.0   \n",
       "1      1  12651.66992  12696.29004  12555.16992  12608.91992  232760000.0   \n",
       "2      0  12605.83008  12675.12012  12527.75000  12626.03027  183870000.0   \n",
       "3      1  12626.03027  12688.48047  12528.16016  12609.41992  181260000.0   \n",
       "4      0  12612.58984  12733.66016  12583.28027  12612.42969  198070000.0   \n",
       "\n",
       "   InterestRate  ExchangeRate    VIX    Gold     Oil  \n",
       "0          1.77        1.5615  22.68  897.00  100.92  \n",
       "1          1.72        1.5618  23.43  893.50  104.83  \n",
       "2          1.70        1.5667  23.21  898.25  103.92  \n",
       "3          1.67        1.5735  22.45  905.25  106.09  \n",
       "4          1.62        1.5713  22.42  914.70  108.91  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"DOW30.csv\")\n",
    "data = data.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Open         High          Low        Close       Volume  \\\n",
      "0  12266.63965  12659.82031  12266.46973  12654.36035  295530000.0   \n",
      "1  12651.66992  12696.29004  12555.16992  12608.91992  232760000.0   \n",
      "2  12605.83008  12675.12012  12527.75000  12626.03027  183870000.0   \n",
      "3  12626.03027  12688.48047  12528.16016  12609.41992  181260000.0   \n",
      "4  12612.58984  12733.66016  12583.28027  12612.42969  198070000.0   \n",
      "\n",
      "   InterestRate  ExchangeRate    VIX    Gold     Oil  \n",
      "0          1.77        1.5615  22.68  897.00  100.92  \n",
      "1          1.72        1.5618  23.43  893.50  104.83  \n",
      "2          1.70        1.5667  23.21  898.25  103.92  \n",
      "3          1.67        1.5735  22.45  905.25  106.09  \n",
      "4          1.62        1.5713  22.42  914.70  108.91  \n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: LABEL, dtype: int64\n",
      "(2448,)\n",
      "(2448, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split data and label\n",
    "data_Y = data['LABEL']\n",
    "data_X = data.drop(['LABEL'],axis=1)\n",
    "print(data_X.head())\n",
    "print(data_Y.head())\n",
    "print(data_Y.shape)\n",
    "print(data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def SVM_trainer(data_X, data_Y):\n",
    "    svm_scaler = StandardScaler()\n",
    "    svm_pca = PCA()\n",
    "    svm = SVC()\n",
    "\n",
    "    svm_ppl = Pipeline(steps=[('scaler', svm_scaler), ('pca', svm_pca), ('svm', svm)])\n",
    "\n",
    "    svm_param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    svm_grid_search = GridSearchCV(svm_ppl, svm_param_grid, cv=5, scoring='accuracy')\n",
    "    svm_scores = cross_val_score(svm_grid_search, data_X, data_Y, cv=10)\n",
    "    svm_preds = cross_val_predict(svm_grid_search, data_X, data_Y, cv=10)\n",
    "    print(\"Accuracy:\", svm_scores.mean()*100, \"%\")\n",
    "    print(\"classification report:\\n\",classification_report(data_Y, svm_preds))\n",
    "    return svm_grid_search\n",
    "\n",
    "# SVM_trainer(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def KNN_trainer(data_X, data_Y):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA()\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "    ppl = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn_classifier)])\n",
    "    scores = cross_val_score(ppl, data_X, data_Y, cv=5) \n",
    "    print(\"Accuracy:\", scores.mean()*100, \"%\")\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'knn__n_neighbors': list(range(1, 26))\n",
    "    }\n",
    "\n",
    "    knn_grid_search = GridSearchCV(ppl, param_grid, cv=5, scoring='accuracy')\n",
    "    knn_grid_search.fit(data_X, data_Y)\n",
    "    print(\"Best parameters:\", knn_grid_search.best_params_)\n",
    "    print(\"Best score:\", knn_grid_search.best_score_*100, \"%\")\n",
    "\n",
    "    knn_nested_score = cross_val_score(knn_grid_search, data_X, data_Y, cv=5)\n",
    "    print(\"Accuracy:\", knn_nested_score.mean()*100, \"%\")\n",
    "    return knn_grid_search\n",
    "# knn_grid_search = KNN_trainer(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "nn_scaler = StandardScaler()\n",
    "nn = MLPClassifier()\n",
    "\n",
    "nn_ppl = Pipeline(steps=[('scaler', nn_scaler), ('nn', nn)])\n",
    "nn_param_grid = {\n",
    "    'nn__hidden_layer_sizes': list(range(30, 61, 10)),\n",
    "    'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def NN_trainer(nn_ppl, nn_param_grid, data_X, data_Y):\n",
    "    nn_grid_search = GridSearchCV(nn_ppl, nn_param_grid, cv=5, scoring='accuracy')\n",
    "    nn_scores = cross_val_score(nn_grid_search, data_X, data_Y, cv=5)\n",
    "    print(\"Accuracy:\", nn_scores.mean()*100, \"%\")\n",
    "    return nn_grid_search\n",
    "\n",
    "# nn_grid_search = NN_trainer(nn_ppl, nn_param_grid, data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, eclf):\n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[('svm', svm_grid_search), ('knn', knn_grid_search), ('nn', nn_grid_search)],\n",
    "        voting='hard')\n",
    "    for clf, label in zip([svm_grid_search, knn_grid_search, nn_grid_search, eclf], ['SVM', 'KNN', 'Neural Network', 'Ensemble']):\n",
    "        scores = cross_val_score(clf, data_X, data_Y, scoring='accuracy', cv=5)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        \n",
    "# ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, eclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.941953830712606 %\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.12      1119\n",
      "           1       0.54      0.94      0.69      1328\n",
      "\n",
      "    accuracy                           0.54      2447\n",
      "   macro avg       0.51      0.50      0.40      2447\n",
      "weighted avg       0.51      0.54      0.43      2447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data_dow = pd.read_csv(\"DOW30.csv\")\n",
    "data_sp = pd.read_csv(\"SP500.csv\")\n",
    "data_nas = pd.read_csv(\"NASDAQ.csv\")\n",
    "\n",
    "def process_data(target_dataset, dataset_label1, dataset_label2, label1, label2):\n",
    "    data_processed = target_dataset.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "    labels1 = dataset_label1.iloc[0:, 1]\n",
    "    labels2 = dataset_label2.iloc[0:, 1]\n",
    "    data_processed[label1] = labels1\n",
    "    data_processed[label1] = data_processed[label1].shift(periods=1, fill_value=-1)\n",
    "    data_processed[label2] = labels2\n",
    "    data_processed[label2] = data_processed[label2].shift(periods=1, fill_value=-1)\n",
    "    data_processed = data_processed.iloc[1: , :]\n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOW30\n",
    "data_dow_processed = process_data(data_dow, data_sp, data_nas, \"SP500\", \"NASDAQ\")\n",
    "# print(dataset_dow_processed.head())\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_X, data_Y)\n",
    "nn_grid_search = NN_trainer(nn_ppl, nn_param_grid, data_X, data_Y)\n",
    "eclf = VotingClassifier(\n",
    "        estimators=[('svm', svm_grid_search), ('knn', knn_grid_search), ('nn', nn_grid_search)],\n",
    "        voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500\n",
    "data_sp_processed = process_data(data_sp, data_dow, data_nas, \"DOW30\", \"NASDAQ\")\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_sp_X, data_sp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = process_data(data_nas, data_dow, data_sp, \"DOW30\", \"SP500\")\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
