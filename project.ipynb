{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final Project\n",
    "Group Members: Jesse Zou, Andy Li, Yuhan Zheng, Zhiyao Bao"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introduction\n",
    "* What is the data science problem you are trying to solve?\n",
    "* * We're trying to predict the trend of the stock market (if the stock market's price will go up or go down in general for the next day) for DOW30, SP500 and NASDAQ respectively.\n",
    "* Why does the problem matter?\n",
    "* * The problem matters because: first, we have an unbiased analysis on the market and the economy; second, it may help people involving the stock market to earn money.\n",
    "* What could the results of your predictive model be used for?\n",
    "* Why would we want to be able to predict the thing youâ€™re trying to predict?\n",
    "* Then describe the dataset that you will use to tackle this problem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Imports\n",
    "import warnings\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "data cleaning\n",
    "data exploration\n",
    "feature engineering\n",
    "describe and clarify each part of the process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Read data\n",
    "data_dow = pd.read_csv(\"DOW30.csv\")\n",
    "data_sp = pd.read_csv(\"SP500.csv\")\n",
    "data_nas = pd.read_csv(\"NASDAQ.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def box_plot(x):\n",
    "    red_square = dict(markerfacecolor='r', marker='s')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Horizontal Boxes')\n",
    "    ax.boxplot(x, vert=False, flierprops=red_square)\n",
    "\n",
    "box_plot(data_dow[\"\"])\n",
    "\n",
    "def line_graph(x, y):\n",
    "    pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM\n",
    "def SVM_trainer(data_X, data_Y):\n",
    "    svm_scaler = StandardScaler()\n",
    "    svm_pca = PCA()\n",
    "    svm = SVC()\n",
    "\n",
    "    svm_ppl = Pipeline(steps=[('scaler', svm_scaler), ('pca', svm_pca), ('svm', svm)])\n",
    "\n",
    "    svm_param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    svm_grid_search = GridSearchCV(svm_ppl, svm_param_grid, cv=5, scoring='accuracy')\n",
    "#     svm_scores = cross_val_score(svm_grid_search, data_X, data_Y, cv=10)\n",
    "#     svm_preds = cross_val_predict(svm_grid_search, data_X, data_Y, cv=10)\n",
    "#     print(\"Accuracy:\", svm_scores.mean()*100, \"%\")\n",
    "#     print(\"classification report:\\n\",classification_report(data_Y, svm_preds))\n",
    "    return svm_grid_search\n",
    "\n",
    "# SVM_trainer(data_X, data_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN\n",
    "def KNN_trainer(data_X, data_Y):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA()\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "    ppl = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn_classifier)])\n",
    "#     scores = cross_val_score(ppl, data_X, data_Y, cv=5) \n",
    "#     print(\"Accuracy:\", scores.mean()*100, \"%\")\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'knn__n_neighbors': list(range(1, 26))\n",
    "    }\n",
    "\n",
    "    knn_grid_search = GridSearchCV(ppl, param_grid, cv=5, scoring='accuracy')\n",
    "#     knn_grid_search.fit(data_X, data_Y)\n",
    "#     print(\"Best parameters:\", knn_grid_search.best_params_)\n",
    "#     print(\"Best score:\", knn_grid_search.best_score_*100, \"%\")\n",
    "\n",
    "#     knn_nested_score = cross_val_score(knn_grid_search, data_X, data_Y, cv=5)\n",
    "#     print(\"Accuracy:\", knn_nested_score.mean()*100, \"%\")\n",
    "    return knn_grid_search\n",
    "# knn_grid_search = KNN_trainer(data_X, data_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NN\n",
    "# @ignore_warnings(category=ConvergenceWarning)\n",
    "def NN_trainer(data_X, data_Y):\n",
    "    nn_scaler = StandardScaler()\n",
    "    nn = MLPClassifier()\n",
    "\n",
    "    nn_ppl = Pipeline(steps=[('scaler', nn_scaler), ('nn', nn)])\n",
    "    nn_param_grid = {\n",
    "        'nn__hidden_layer_sizes': list(range(30, 61, 10)),\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "    nn_grid_search = GridSearchCV(nn_ppl, nn_param_grid, cv=5, scoring='accuracy')\n",
    "#     nn_scores = cross_val_score(nn_grid_search, data_X, data_Y, cv=5)\n",
    "#     print(\"Accuracy:\", nn_scores.mean()*100, \"%\")\n",
    "    return nn_grid_search\n",
    "\n",
    "# nn_grid_search = NN_trainer(nn_ppl, nn_param_grid, data_X, data_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Ensamble\n",
    "# @ignore_warnings(category=ConvergenceWarning)\n",
    "def ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_X, data_Y):\n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[('svm', svm_grid_search), ('knn', knn_grid_search), ('nn', nn_grid_search)],\n",
    "        voting='hard')\n",
    "    for clf, label in zip([svm_grid_search, knn_grid_search, nn_grid_search, eclf], ['SVM', 'KNN', 'Neural Network', 'Ensemble']):\n",
    "        scores = cross_val_score(clf, data_X, data_Y, scoring='accuracy', cv=5)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        \n",
    "# ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, eclf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results with Various Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1: without tracking the prev day; no date, TEDSpread, EFFR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DOW30\n",
    "data_dow_processed = data_dow.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "# data_dow_processed.head()\n",
    "\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_dow_X, data_dow_Y)\n",
    "nn_grid_search = NN_trainer(data_dow_X, data_dow_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_dow_X, data_dow_Y)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SP500\n",
    "data_sp_processed = data_sp.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_sp_X, data_sp_Y)\n",
    "knn_grid_search = KNN_trainer(data_sp_X, data_sp_Y)\n",
    "nn_grid_search = NN_trainer(data_sp_X, data_sp_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_sp_X, data_sp_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = data_nas.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)\n",
    "svm_grid_search = SVM_trainer(data_nas_X, data_nas_Y)\n",
    "knn_grid_search = KNN_trainer(data_nas_X, data_nas_Y)\n",
    "nn_grid_search = NN_trainer(data_nas_X, data_nas_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_nas_X, data_nas_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2: tracking the prev day; no date, TEDSpread, EFFR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# preprocess data\n",
    "def process_data(target_dataset, dataset_label1, dataset_label2, label1, label2):\n",
    "    data_processed = target_dataset.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "    labels1 = dataset_label1.iloc[0:, 1]\n",
    "    labels2 = dataset_label2.iloc[0:, 1]\n",
    "    data_processed[label1] = labels1\n",
    "    data_processed[label1] = data_processed[label1].shift(periods=1, fill_value=-1)\n",
    "    data_processed[label2] = labels2\n",
    "    data_processed[label2] = data_processed[label2].shift(periods=1, fill_value=-1)\n",
    "    data_processed = data_processed.iloc[1: , :]\n",
    "    return data_processed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DOW30\n",
    "data_dow_processed = process_data(data_dow, data_sp, data_nas, \"SP500\", \"NASDAQ\")\n",
    "# print(data_dow_processed.head())\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_dow_X, data_dow_Y)\n",
    "nn_grid_search = NN_trainer(data_dow_X, data_dow_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_dow_X, data_dow_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SP500\n",
    "data_sp_processed = process_data(data_sp, data_dow, data_nas, \"DOW30\", \"NASDAQ\")\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_sp_X, data_sp_Y)\n",
    "knn_grid_search = KNN_trainer(data_sp_X, data_sp_Y)\n",
    "nn_grid_search = NN_trainer(data_sp_X, data_sp_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_sp_X, data_sp_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = process_data(data_nas, data_dow, data_sp, \"DOW30\", \"SP500\")\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)\n",
    "svm_grid_search = SVM_trainer(data_nas_X, data_nas_Y)\n",
    "knn_grid_search = KNN_trainer(data_nas_X, data_nas_Y)\n",
    "nn_grid_search = NN_trainer(data_nas_X, data_nas_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_nas_X, data_nas_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2: tracking the prev day; no date"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# preprocess data\n",
    "def process_data_2(target_dataset, dataset_label1, dataset_label2, label1, label2):\n",
    "    data_processed = target_dataset.drop(['Date'],axis=1)\n",
    "    labels1 = dataset_label1.iloc[0:, 1]\n",
    "    labels2 = dataset_label2.iloc[0:, 1]\n",
    "    data_processed[label1] = labels1\n",
    "    data_processed[label1] = data_processed[label1].shift(periods=1, fill_value=-1)\n",
    "    data_processed[label2] = labels2\n",
    "    data_processed[label2] = data_processed[label2].shift(periods=1, fill_value=-1)\n",
    "    data_processed = data_processed.iloc[1: , :]\n",
    "    return data_processed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# DOW30\n",
    "data_dow_processed = process_data_2(data_dow, data_sp, data_nas, \"SP500\", \"NASDAQ\")\n",
    "# print(data_dow_processed.head())\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_dow_X, data_dow_Y)\n",
    "nn_grid_search = NN_trainer(data_dow_X, data_dow_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_dow_X, data_dow_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SP500\n",
    "data_sp_processed = process_data_2(data_sp, data_dow, data_nas, \"DOW30\", \"NASDAQ\")\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_sp_X, data_sp_Y)\n",
    "knn_grid_search = KNN_trainer(data_sp_X, data_sp_Y)\n",
    "nn_grid_search = NN_trainer(data_sp_X, data_sp_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_sp_X, data_sp_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = process_data_2(data_nas, data_dow, data_sp, \"DOW30\", \"SP500\")\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)\n",
    "svm_grid_search = SVM_trainer(data_nas_X, data_nas_Y)\n",
    "knn_grid_search = KNN_trainer(data_nas_X, data_nas_Y)\n",
    "nn_grid_search = NN_trainer(data_nas_X, data_nas_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_nas_X, data_nas_Y)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}