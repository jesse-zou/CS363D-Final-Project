{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project\n",
    "Group Members: Jesse Zou, Andy Li, Yuhan Zheng, Zhiyao Bao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "What is the data science problem you are trying to solve?\n",
    "Why does the problem matter?\n",
    "What could the results of your predictive model be used for?\n",
    "Why would we want to be able to predict the thing youâ€™re trying to predict?\n",
    "Then describe the dataset that you will use to tackle this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data cleaning\n",
    "data exploration\n",
    "feature engineering\n",
    "describe and clarify each part of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def SVM_trainer(data_X, data_Y):\n",
    "    svm_scaler = StandardScaler()\n",
    "    svm_pca = PCA()\n",
    "    svm = SVC()\n",
    "\n",
    "    svm_ppl = Pipeline(steps=[('scaler', svm_scaler), ('pca', svm_pca), ('svm', svm)])\n",
    "\n",
    "    svm_param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "\n",
    "    svm_grid_search = GridSearchCV(svm_ppl, svm_param_grid, cv=5, scoring='accuracy')\n",
    "#     svm_scores = cross_val_score(svm_grid_search, data_X, data_Y, cv=10)\n",
    "#     svm_preds = cross_val_predict(svm_grid_search, data_X, data_Y, cv=10)\n",
    "#     print(\"Accuracy:\", svm_scores.mean()*100, \"%\")\n",
    "#     print(\"classification report:\\n\",classification_report(data_Y, svm_preds))\n",
    "    return svm_grid_search\n",
    "\n",
    "# SVM_trainer(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def KNN_trainer(data_X, data_Y):\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA()\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=7)\n",
    "    ppl = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn_classifier)])\n",
    "#     scores = cross_val_score(ppl, data_X, data_Y, cv=5) \n",
    "#     print(\"Accuracy:\", scores.mean()*100, \"%\")\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 11)),\n",
    "        'knn__n_neighbors': list(range(1, 26))\n",
    "    }\n",
    "\n",
    "    knn_grid_search = GridSearchCV(ppl, param_grid, cv=5, scoring='accuracy')\n",
    "#     knn_grid_search.fit(data_X, data_Y)\n",
    "#     print(\"Best parameters:\", knn_grid_search.best_params_)\n",
    "#     print(\"Best score:\", knn_grid_search.best_score_*100, \"%\")\n",
    "\n",
    "#     knn_nested_score = cross_val_score(knn_grid_search, data_X, data_Y, cv=5)\n",
    "#     print(\"Accuracy:\", knn_nested_score.mean()*100, \"%\")\n",
    "    return knn_grid_search\n",
    "# knn_grid_search = KNN_trainer(data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def NN_trainer(data_X, data_Y):\n",
    "    nn_scaler = StandardScaler()\n",
    "    nn = MLPClassifier()\n",
    "\n",
    "    nn_ppl = Pipeline(steps=[('scaler', nn_scaler), ('nn', nn)])\n",
    "    nn_param_grid = {\n",
    "        'nn__hidden_layer_sizes': list(range(30, 61, 10)),\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "    nn_grid_search = GridSearchCV(nn_ppl, nn_param_grid, cv=5, scoring='accuracy')\n",
    "#     nn_scores = cross_val_score(nn_grid_search, data_X, data_Y, cv=5)\n",
    "#     print(\"Accuracy:\", nn_scores.mean()*100, \"%\")\n",
    "    return nn_grid_search\n",
    "\n",
    "# nn_grid_search = NN_trainer(nn_ppl, nn_param_grid, data_X, data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensamble\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_X, data_Y):\n",
    "    eclf = VotingClassifier(\n",
    "        estimators=[('svm', svm_grid_search), ('knn', knn_grid_search), ('nn', nn_grid_search)],\n",
    "        voting='hard')\n",
    "    for clf, label in zip([svm_grid_search, knn_grid_search, nn_grid_search, eclf], ['SVM', 'KNN', 'Neural Network', 'Ensemble']):\n",
    "        scores = cross_val_score(clf, data_X, data_Y, scoring='accuracy', cv=5)\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        \n",
    "# ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_dow = pd.read_csv(\"DOW30.csv\")\n",
    "data_sp = pd.read_csv(\"SP500.csv\")\n",
    "data_nas = pd.read_csv(\"NASDAQ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with Various Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: without tracking the prev day; no date, TEDSpread, EFFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.50 (+/- 0.03) [KNN]\n",
      "Accuracy: 0.52 (+/- 0.04) [Neural Network]\n",
      "Accuracy: 0.53 (+/- 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# DOW30\n",
    "data_dow_processed = data_dow.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "# data_dow_processed.head()\n",
    "\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_dow_X, data_dow_Y)\n",
    "nn_grid_search = NN_trainer(data_dow_X, data_dow_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_dow_X, data_dow_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.04) [SVM]\n",
      "Accuracy: 0.50 (+/- 0.02) [KNN]\n",
      "Accuracy: 0.53 (+/- 0.03) [Neural Network]\n",
      "Accuracy: 0.51 (+/- 0.04) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# SP500\n",
    "data_sp_processed = data_sp.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_sp_X, data_sp_Y)\n",
    "knn_grid_search = KNN_trainer(data_sp_X, data_sp_Y)\n",
    "nn_grid_search = NN_trainer(data_sp_X, data_sp_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_sp_X, data_sp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.47 (+/- 0.04) [KNN]\n",
      "Accuracy: 0.56 (+/- 0.00) [Neural Network]\n",
      "Accuracy: 0.55 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = data_nas.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)\n",
    "svm_grid_search = SVM_trainer(data_nas_X, data_nas_Y)\n",
    "knn_grid_search = KNN_trainer(data_nas_X, data_nas_Y)\n",
    "nn_grid_search = NN_trainer(data_nas_X, data_nas_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_nas_X, data_nas_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: tracking the prev day; no date, TEDSpread, EFFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "def process_data(target_dataset, dataset_label1, dataset_label2, label1, label2):\n",
    "    data_processed = target_dataset.drop(['Date', 'TEDSpread', 'EFFR'],axis=1)\n",
    "    labels1 = dataset_label1.iloc[0:, 1]\n",
    "    labels2 = dataset_label2.iloc[0:, 1]\n",
    "    data_processed[label1] = labels1\n",
    "    data_processed[label1] = data_processed[label1].shift(periods=1, fill_value=-1)\n",
    "    data_processed[label2] = labels2\n",
    "    data_processed[label2] = data_processed[label2].shift(periods=1, fill_value=-1)\n",
    "    data_processed = data_processed.iloc[1: , :]\n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53 (+/- 0.01) [SVM]\n",
      "Accuracy: 0.51 (+/- 0.03) [KNN]\n",
      "Accuracy: 0.52 (+/- 0.03) [Neural Network]\n",
      "Accuracy: 0.53 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# DOW30\n",
    "data_dow_processed = process_data(data_dow, data_sp, data_nas, \"SP500\", \"NASDAQ\")\n",
    "# print(data_dow_processed.head())\n",
    "data_dow_Y = data_dow_processed['LABEL']\n",
    "data_dow_X = data_dow_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_dow_X, data_dow_Y)\n",
    "knn_grid_search = KNN_trainer(data_dow_X, data_dow_Y)\n",
    "nn_grid_search = NN_trainer(data_dow_X, data_dow_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_dow_X, data_dow_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.50 (+/- 0.02) [KNN]\n",
      "Accuracy: 0.54 (+/- 0.01) [Neural Network]\n",
      "Accuracy: 0.54 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# SP500\n",
    "data_sp_processed = process_data(data_sp, data_dow, data_nas, \"DOW30\", \"NASDAQ\")\n",
    "data_sp_Y = data_sp_processed['LABEL']\n",
    "data_sp_X = data_sp_processed.drop(['LABEL'],axis=1)\n",
    "svm_grid_search = SVM_trainer(data_sp_X, data_sp_Y)\n",
    "knn_grid_search = KNN_trainer(data_sp_X, data_sp_Y)\n",
    "nn_grid_search = NN_trainer(data_sp_X, data_sp_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_sp_X, data_sp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55 (+/- 0.02) [SVM]\n",
      "Accuracy: 0.50 (+/- 0.04) [KNN]\n",
      "Accuracy: 0.56 (+/- 0.00) [Neural Network]\n",
      "Accuracy: 0.54 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# NASDAQ\n",
    "data_nas_processed = process_data(data_nas, data_dow, data_sp, \"DOW30\", \"SP500\")\n",
    "data_nas_Y = data_nas_processed['LABEL']\n",
    "data_nas_X = data_nas_processed.drop(['LABEL'],axis=1)\n",
    "SVM_trainer(data_nas_X, data_nas_Y)\n",
    "svm_grid_search = SVM_trainer(data_nas_X, data_nas_Y)\n",
    "knn_grid_search = KNN_trainer(data_nas_X, data_nas_Y)\n",
    "nn_grid_search = NN_trainer(data_nas_X, data_nas_Y)\n",
    "ensamble_trainer(svm_grid_search, knn_grid_search, nn_grid_search, data_nas_X, data_nas_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
